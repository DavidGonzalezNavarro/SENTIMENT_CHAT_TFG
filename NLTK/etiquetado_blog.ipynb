{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tag | Prec.  | Recall | F-measure\n",
      "-------+--------+--------+-----------\n",
      "    '' | 1.0000 | 1.0000 | 1.0000\n",
      "     , | 1.0000 | 1.0000 | 1.0000\n",
      "-NONE- | 0.0000 | 0.0000 | 0.0000\n",
      "     . | 1.0000 | 1.0000 | 1.0000\n",
      "     : | 1.0000 | 1.0000 | 1.0000\n",
      "    CC | 1.0000 | 1.0000 | 1.0000\n",
      "    CD | 0.7647 | 1.0000 | 0.8667\n",
      "    DT | 1.0000 | 1.0000 | 1.0000\n",
      "    IN | 1.0000 | 1.0000 | 1.0000\n",
      "    JJ | 0.5882 | 0.8333 | 0.6897\n",
      "   JJR | 1.0000 | 1.0000 | 1.0000\n",
      "   JJS | 1.0000 | 1.0000 | 1.0000\n",
      "    NN | 0.7647 | 0.9630 | 0.8525\n",
      "   NNP | 0.8929 | 1.0000 | 0.9434\n",
      "   NNS | 1.0000 | 1.0000 | 1.0000\n",
      "   POS | 1.0000 | 1.0000 | 1.0000\n",
      "   PRP | 1.0000 | 1.0000 | 1.0000\n",
      "    RB | 0.8000 | 1.0000 | 0.8889\n",
      "   RBR | 0.0000 | 0.0000 | 0.0000\n",
      "    TO | 1.0000 | 1.0000 | 1.0000\n",
      "    VB | 1.0000 | 1.0000 | 1.0000\n",
      "   VBD | 0.8571 | 0.9231 | 0.8889\n",
      "   VBG | 1.0000 | 1.0000 | 1.0000\n",
      "   VBN | 0.8333 | 0.5556 | 0.6667\n",
      "   VBP | 0.5714 | 0.8000 | 0.6667\n",
      "   VBZ | 1.0000 | 1.0000 | 1.0000\n",
      "    WP | 1.0000 | 1.0000 | 1.0000\n",
      "    `` | 1.0000 | 1.0000 | 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import PerceptronTagger\n",
    "from nltk.corpus import treebank\n",
    "tagger = PerceptronTagger()\n",
    "gold_data = treebank.tagged_sents()[10:20]\n",
    "print(tagger.evaluate_per_tag(gold_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRP'), ('perdido', 'VBZ'), ('el', 'JJ'), ('perro', 'NN'), ('y', 'NN'), ('lo', 'NN'), ('he', 'PRP'), ('encontrado', 'VBZ'), ('en', 'JJ'), ('el', 'NN'), ('parque', 'NN')]\n",
      "[('La', 'NNP'), ('sociedad', 'VBD'), ('mas', 'FW'), ('conectada', 'NN'), ('es', 'NN'), ('la', 'NN'), ('sociedad', 'FW'), ('donde', 'NN'), ('el', 'FW'), ('ser', 'NN'), ('humana', 'NN'), ('ha', 'NN'), ('experimentado', 'FW'), ('mas', 'NN'), ('la', 'NN'), ('soledad', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "oracion1 = \"He perdido el perro y lo he encontrado en el parque\"\n",
    "string_oracion1 = wordpunct_tokenize(oracion1)\n",
    "oracion2 = \"The progress of the humankind as I progress\"\n",
    "oracion2 = \"La sociedad mas conectada es la sociedad donde el ser humana ha experimentado mas la soledad.\"\n",
    "string_oracion2 = wordpunct_tokenize(oracion2)\n",
    "print(pos_tag(string_oracion1))\n",
    "print(pos_tag(string_oracion2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouput:\n",
    "[('He', 'PRP'), ('perdido', 'VBZ'), ('el', 'JJ'), ('perro', 'NN'), ('y', 'NN'), ('lo', 'NN'), ('he', 'PRP'), ('encontrado', 'VBZ'), ('en', 'JJ'), ('el', 'NN'), ('parque', 'NN')]\n",
    "[('La', 'NNP'), ('sociedad', 'VBD'), ('mas', 'FW'), ('conectada', 'NN'), ('es', 'NN'), ('la', 'NN'), ('sociedad', 'FW'), ('donde', 'NN'), ('el', 'FW'), ('ser', 'NN'), ('humana', 'NN'), ('ha', 'NN'), ('experimentado', 'FW'), ('mas', 'NN'), ('la', 'NN'), ('soledad', 'NN'), ('.', '.')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
